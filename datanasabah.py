# -*- coding: utf-8 -*-
"""datanasabah.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NtZJh3Tu5qn44VFR9qmhGZwhvxdepep1
"""

from google.colab import drive
drive.mount('/content/drive')

data = pd.read_csv('/content/drive/MyDrive/datanasabah.csv')
print(data.head())

# Jumlah data (jumlah baris dan kolom)
print("Jumlah baris dan kolom:", data.shape)

# Tipe data setiap kolom
print("\nTipe data setiap kolom:")
print(data.dtypes)

# Informasi deskriptif (statistik ringkasan)
print("\nStatistik deskriptif:")
print(data.describe(include='all'))

# Informasi tentang kolom non-null dan penggunaan memori
print("\nInformasi data:")
data.info()

import pandas as pd

# Menampilkan jumlah nilai unik untuk setiap kolom (untuk memahami kategori)
print("\nJumlah nilai unik untuk setiap kolom:")
for column in data.columns:
    print(f"{column}: {data[column].nunique()}")

# Melakukan pengkodean pada kolom kategorikal
data['jenis_kelamin'] = data['jenis_kelamin'].map({'Laki-Laki': 1, 'Perempuan': 2})
data['jenis_produk'] = data['jenis_produk'].map({'tabungan': 1, 'kartu_kredit': 2, 'deposito': 3})
data['pengguna_mobile_banking'] = data['pengguna_mobile_banking'].map({'YA': 1, 'TIDAK': 2})
print(data.head()) # Memastikan perubahan

"""# Task
Lakukan eksplorasi data mendalam pada dataset "Data_Nasabah.csv" yang sudah terhubung dari Google Drive ke Google Colab, mencakup penanganan nilai yang hilang dan duplikat, analisis univariat, bivariat, dan multivariat (jika relevan), serta ringkasan temuan.

## Memahami data

### Subtask:
Tinjau kembali informasi data yang sudah didapatkan (jumlah data, tipe data, statistik deskriptif, jumlah nilai unik) untuk mendapatkan gambaran awal.

## Menangani nilai yang hilang (missing values)

### Subtask:
Periksa apakah ada nilai yang hilang dalam dataset dan tentukan strategi untuk menanganinya (misalnya, mengisi dengan nilai tertentu, menghapus baris/kolom).

**Reasoning**:
Check for missing values in each column and display the count of missing values per column.
"""

print("\nMissing values per column:")
print(data.isnull().sum())

"""## Menangani nilai duplikat

### Subtask:
Periksa dan tangani baris yang mungkin terduplikasi.

**Reasoning**:
Check for duplicate rows, count them, remove them if they exist, and then verify the removal.
"""

print("\nNumber of duplicate rows before dropping:", data.duplicated().sum())
data.drop_duplicates(inplace=True)
print("Number of duplicate rows after dropping:", data.duplicated().sum())

"""## Analisis univariat

### Subtask:
Lakukan analisis pada setiap kolom secara individual. Ini bisa melibatkan:
- Visualisasi distribusi data (histogram, box plot).
- Menghitung ukuran pemusatan (mean, median, mode) dan penyebaran (standar deviasi, variance, range).
- Mengidentifikasi outlier.

**Reasoning**:
Generate histograms and box plots for numerical columns to visualize their distributions and identify potential outliers, and calculate summary statistics (mean, median, std) for these columns.
"""

import matplotlib.pyplot as plt
import seaborn as sns

numerical_cols = ['umur', 'pendapatan', 'saldo_rata_rata', 'jumlah_transaksi', 'frekuensi_kunjungi_cabang', 'skor_kredit']

# Histograms
plt.figure(figsize=(15, 10))
for i, col in enumerate(numerical_cols):
    plt.subplot(3, 2, i + 1)
    sns.histplot(data[col], kde=True)
    plt.title(f'Distribution of {col}')
plt.tight_layout()
plt.show()

# Box plots
plt.figure(figsize=(15, 10))
for i, col in enumerate(numerical_cols):
    plt.subplot(3, 2, i + 1)
    sns.boxplot(x=data[col])
    plt.title(f'Box Plot of {col}')
plt.tight_layout()
plt.show()

# Summary statistics
print("\nSummary Statistics for Numerical Columns:")
for col in numerical_cols:
    print(f"{col}:")
    print(f"  Mean: {data[col].mean():.2f}")
    print(f"  Median: {data[col].median():.2f}")
    print(f"  Standard Deviation: {data[col].std():.2f}")
    print("-" * 20)

"""**Reasoning**:
Calculate and display the frequency counts for the categorical columns to understand the distribution of categories.


"""

categorical_cols = ['jenis_kelamin', 'jenis_produk', 'pengguna_mobile_banking']

print("\nFrequency Counts for Categorical Columns:")
for col in categorical_cols:
    print(f"\n{col}:")
    print(data[col].value_counts())

"""## Analisis bivariat

### Subtask:
Lakukan analisis untuk memahami hubungan antara dua kolom. Ini bisa melibatkan:
- Membuat scatter plot, bar plot, atau box plot untuk melihat hubungan antar variabel.
- Menghitung korelasi antar variabel numerik.

**Reasoning**:
Create scatter plots for pairs of numerical columns, box plots for categorical vs numerical columns, calculate the correlation matrix, and display it as a heatmap to understand the relationships between variables.
"""

import matplotlib.pyplot as plt
import seaborn as sns

numerical_cols = ['umur', 'pendapatan', 'saldo_rata_rata', 'jumlah_transaksi', 'frekuensi_kunjungi_cabang', 'skor_kredit']
categorical_cols = ['jenis_kelamin', 'jenis_produk', 'pengguna_mobile_banking']

# Scatter plots for numerical pairs
plt.figure(figsize=(18, 15))
for i in range(len(numerical_cols)):
    for j in range(i + 1, len(numerical_cols)):
        plt.subplot(5, 3, i * (len(numerical_cols) - 1) + j)
        sns.scatterplot(data=data, x=numerical_cols[i], y=numerical_cols[j])
        plt.title(f'{numerical_cols[i]} vs {numerical_cols[j]}')
plt.tight_layout()
plt.show()

# Box plots for categorical vs numerical columns
plt.figure(figsize=(15, 15))
plot_index = 1
for cat_col in categorical_cols:
    for num_col in numerical_cols:
        plt.subplot(len(categorical_cols), len(numerical_cols), plot_index)
        sns.boxplot(data=data, x=cat_col, y=num_col)
        plt.title(f'{cat_col} vs {num_col}')
        plot_index += 1
plt.tight_layout()
plt.show()

# Correlation matrix
correlation_matrix = data[numerical_cols].corr()

# Display correlation matrix as a heatmap
plt.figure(figsize=(10, 8))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f")
plt.title('Correlation Matrix of Numerical Columns')
plt.show()

print("\nCorrelation Matrix:")
display(correlation_matrix)

"""**Reasoning**:
The previous attempt to create scatter plots failed due to an incorrect subplot index calculation. The number of possible unique pairs of numerical columns is (n * (n-1)) / 2, where n is the number of numerical columns. The subplot layout needs to accommodate this number of plots. I will recalculate the subplot layout based on the number of unique pairs and regenerate the plots. I will also ensure the subsequent box plots and correlation matrix steps are included in the same code block as they are part of the same subtask.


"""

import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

numerical_cols = ['umur', 'pendapatan', 'saldo_rata_rata', 'jumlah_transaksi', 'frekuensi_kunjungi_cabang', 'skor_kredit']
categorical_cols = ['jenis_kelamin', 'jenis_produk', 'pengguna_mobile_banking']

# Scatter plots for numerical pairs
num_numerical_cols = len(numerical_cols)
num_scatter_plots = int(num_numerical_cols * (num_numerical_cols - 1) / 2)
n_cols_scatter = 3 # Number of columns for scatter plots
n_rows_scatter = int(np.ceil(num_scatter_plots / n_cols_scatter)) # Number of rows for scatter plots

plt.figure(figsize=(n_cols_scatter * 5, n_rows_scatter * 5))
plot_index = 1
for i in range(num_numerical_cols):
    for j in range(i + 1, num_numerical_cols):
        plt.subplot(n_rows_scatter, n_cols_scatter, plot_index)
        sns.scatterplot(data=data, x=numerical_cols[i], y=numerical_cols[j])
        plt.title(f'{numerical_cols[i]} vs {numerical_cols[j]}')
        plot_index += 1
plt.tight_layout()
plt.show()

# Box plots for categorical vs numerical columns
num_cat_cols = len(categorical_cols)
num_num_cols = len(numerical_cols)
plt.figure(figsize=(num_num_cols * 4, num_cat_cols * 4))
plot_index = 1
for cat_col in categorical_cols:
    for num_col in numerical_cols:
        plt.subplot(num_cat_cols, num_num_cols, plot_index)
        sns.boxplot(data=data, x=cat_col, y=num_col)
        plt.title(f'{cat_col} vs {num_col}')
        plot_index += 1
plt.tight_layout()
plt.show()

# Correlation matrix
correlation_matrix = data[numerical_cols].corr()

# Display correlation matrix as a heatmap
plt.figure(figsize=(10, 8))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f")
plt.title('Correlation Matrix of Numerical Columns')
plt.show()

print("\nCorrelation Matrix:")
display(correlation_matrix)

"""## Analisis multivariat (opsional)

### Subtask:
Jika relevan, eksplorasi hubungan antara lebih dari dua kolom.

**Reasoning**:
Based on the bivariate analysis, there are some interesting relationships between numerical variables (e.g., income and average balance) and between categorical and numerical variables. A pair plot can be used to visualize the pairwise relationships while also considering the influence of a categorical variable, which is a form of multivariate analysis. This is relevant and beneficial to further understand the data.
"""

import matplotlib.pyplot as plt
import seaborn as sns

# Choose a categorical variable to use for hue in the pair plot
categorical_hue = 'jenis_kelamin' # Or 'jenis_produk', 'pengguna_mobile_banking'

# Create a pair plot to visualize pairwise relationships colored by the chosen categorical variable
sns.pairplot(data, hue=categorical_hue, vars=numerical_cols)
plt.suptitle(f'Pair Plot of Numerical Variables colored by {categorical_hue}', y=1.02) # Adjust title position
plt.show()

"""**Reasoning**:
The pair plot provides a visual overview of the pairwise relationships between numerical variables, colored by the chosen categorical variable. To further explore multivariate relationships, especially considering potential dimensionality reduction or identifying underlying patterns, Principal Component Analysis (PCA) could be a relevant method. This will allow us to see if the data can be represented in a lower-dimensional space while retaining important variance, which is useful for understanding the overall structure of the data.


"""

from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Select numerical columns for PCA
numerical_data = data[numerical_cols]

# Standardize the numerical data before applying PCA
scaler = StandardScaler()
scaled_numerical_data = scaler.fit_transform(numerical_data)

# Apply PCA
pca = PCA()
principal_components = pca.fit_transform(scaled_numerical_data)

# Create a DataFrame with the principal components
pca_df = pd.DataFrame(data=principal_components, columns=[f'PC{i+1}' for i in range(principal_components.shape[1])])

# Add the categorical variable back to the PCA DataFrame for visualization
pca_df['jenis_kelamin'] = data['jenis_kelamin']
pca_df['jenis_produk'] = data['jenis_produk']
pca_df['pengguna_mobile_banking'] = data['pengguna_mobile_banking']


# Explained variance ratio
print("Explained variance ratio by each principal component:")
print(pca.explained_variance_ratio_)

# Cumulative explained variance ratio
print("\nCumulative explained variance ratio:")
print(pca.explained_variance_ratio_.cumsum())

# Visualize the first two principal components, colored by a categorical variable
plt.figure(figsize=(10, 7))
sns.scatterplot(x='PC1', y='PC2', hue='jenis_kelamin', data=pca_df)
plt.title('PCA: First two principal components colored by Jenis Kelamin')
plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]*100:.2f}%)')
plt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]*100:.2f}%)')
plt.show()

plt.figure(figsize=(10, 7))
sns.scatterplot(x='PC1', y='PC2', hue='jenis_produk', data=pca_df)
plt.title('PCA: First two principal components colored by Jenis Produk')
plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]*100:.2f}%)')
plt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]*100:.2f}%)')
plt.show()

plt.figure(figsize=(10, 7))
sns.scatterplot(x='PC1', y='PC2', hue='pengguna_mobile_banking', data=pca_df)
plt.title('PCA: First two principal components colored by Pengguna Mobile Banking')
plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]*100:.2f}%)')
plt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]*100:.2f}%)')
plt.show()

"""## Ringkasan temuan

### Subtask:
Sajikan temuan-temuan kunci dari eksplorasi data dalam format yang mudah dipahami.

**Reasoning**:
Summarize the key findings from all previous exploration steps to present a comprehensive overview of the data and the insights gained.
"""

print("## Ringkasan Temuan Eksplorasi Data")
print("\n### 1. Karakteristik Dataset")
print("- Jumlah observasi (baris): 100")
print("- Jumlah variabel (kolom): 10")
print("- Tipe data meliputi numerik (int64) dan kategorikal (object).")
print("- Tidak ada nilai yang hilang (missing values) dalam dataset.")
print("- Tidak ada baris yang terduplikasi dalam dataset.")

print("\n### 2. Temuan dari Analisis Univariat")
print("- Distribusi variabel numerik ('umur', 'pendapatan', 'saldo_rata_rata', 'jumlah_transaksi', 'frekuensi_kunjungi_cabang', 'skor_kredit') bervariasi.")
print("- Beberapa variabel numerik menunjukkan potensi adanya outlier berdasarkan box plot.")
print("- Variabel kategorikal ('jenis_kelamin', 'jenis_produk', 'pengguna_mobile_banking') memiliki distribusi frekuensi yang menunjukkan jumlah kategori dan sebarannya.")

print("\n### 3. Temuan dari Analisis Bivariat")
print("- Scatter plot menunjukkan hubungan antar pasangan variabel numerik. Terlihat korelasi positif yang cukup kuat antara 'pendapatan' dan 'saldo_rata_rata'.")
print("- Box plot menunjukkan distribusi variabel numerik berdasarkan kategori. Terdapat perbedaan distribusi pada beberapa variabel numerik antar kategori 'jenis_kelamin', 'jenis_produk', dan 'pengguna_mobile_banking'.")
print("- Matriks korelasi mengkonfirmasi hubungan linear antar variabel numerik. 'Pendapatan' dan 'saldo_rata_rata' memiliki korelasi positif tertinggi (0.61).")

print("\n### 4. Temuan dari Analisis Multivariat (PCA)")
print("- Pair plot variabel numerik yang diwarnai berdasarkan variabel kategorikal membantu memvisualisasikan hubungan berpasangan antar variabel dengan mempertimbangkan kategori.")
print("- PCA menunjukkan bahwa dua komponen utama pertama menjelaskan sekitar 48.96% dari total varians. Ini menunjukkan bahwa dua komponen ini tidak sepenuhnya merepresentasikan data asli, dan mungkin diperlukan lebih banyak komponen.")
print("- Scatter plot PC1 vs PC2 diwarnai berdasarkan variabel kategorikal tidak menunjukkan pemisahan klaster yang sangat jelas berdasarkan 'jenis_kelamin' atau 'pengguna_mobile_banking'. Ada indikasi pemisahan yang lebih terlihat berdasarkan 'jenis_produk' pada ruang dimensi yang direduksi, meskipun tidak sepenuhnya terpisah.")

"""## Summary:

### Data Analysis Key Findings

*   The dataset contains 100 observations and 10 variables with numerical (int64) and categorical (object) data types.
*   There were no missing values or duplicate rows found in the dataset.
*   Univariate analysis revealed varying distributions for numerical variables, with potential outliers observed in some. Categorical variables showed their respective frequency distributions.
*   Bivariate analysis indicated a moderately strong positive correlation (0.61) between 'pendapatan' and 'saldo\_rata\_rata'. Box plots showed differences in numerical variable distributions across categories like 'jenis\_kelamin', 'jenis\_produk', and 'pengguna\_mobile\_banking'.
*   Multivariate analysis using PCA showed that the first two principal components explain approximately 48.96% of the total variance. Scatter plots of the first two principal components colored by categorical variables did not show very clear clustering based on 'jenis\_kelamin' or 'pengguna\_mobile\_banking', but there was a slight indication of separation based on 'jenis\_produk'.

### Insights or Next Steps

*   Further investigation into the identified outliers in numerical variables is recommended to determine their impact and decide on appropriate handling strategies.
*   Exploring the relationships between 'jenis\_produk' and numerical variables in more detail could provide insights into how product type influences customer financial behavior.

# Task
Lakukan validasi data yang mendalam dan detail terhadap dataset "Data_Nasabah.csv" yang sudah dimuat.

## Memahami struktur dan tipe data

### Subtask:
Tinjau kembali informasi data yang sudah didapatkan (jumlah data, tipe data, statistik deskriptif, jumlah nilai unik) untuk mendapatkan gambaran awal.

**Reasoning**:
Print the shape, data types, descriptive statistics, and unique value counts of the DataFrame to get an initial overview of the data as requested by the subtask instructions.
"""

print("Jumlah baris dan kolom:", data.shape)
print("\nTipe data setiap kolom:")
print(data.dtypes)
print("\nStatistik deskriptif:")
print(data.describe(include='all'))
print("\nJumlah nilai unik untuk setiap kolom:")
for column in data.columns:
    print(f"{column}: {data[column].nunique()}")

"""## Validasi kelengkapan data

### Subtask:
Periksa keberadaan nilai yang hilang (missing values) dan tentukan strategi penanganannya jika ada.

**Reasoning**:
Check for missing values in each column and display the count of missing values per column.
"""

print("\nMissing values per column:")
print(data.isnull().sum())

"""## Validasi keunikan data

### Subtask:
Periksa dan tangani baris yang mungkin terduplikasi.

**Reasoning**:
Check for duplicate rows, count them, remove them if they exist, and then verify the removal.
"""

print("\nNumber of duplicate rows before dropping:", data.duplicated().sum())
data.drop_duplicates(inplace=True)
print("Number of duplicate rows after dropping:", data.duplicated().sum())

"""## Validasi distribusi data

### Subtask:
Lakukan analisis univariat untuk memahami sebaran nilai dalam setiap kolom. Ini bisa melibatkan:
- Visualisasi distribusi data (histogram, box plot).
- Menghitung ukuran pemusatan (mean, median, mode) dan penyebaran (standar deviasi, variance, range).
- Mengidentifikasi outlier.

**Reasoning**:
Generate histograms and box plots for numerical columns to visualize their distributions and identify potential outliers, and calculate summary statistics (mean, median, std) for these columns. Then, calculate and display the frequency counts for the categorical columns to understand the distribution of categories.
"""

numerical_cols = ['umur', 'pendapatan', 'saldo_rata_rata', 'jumlah_transaksi', 'frekuensi_kunjungi_cabang', 'skor_kredit']

# Histograms
plt.figure(figsize=(15, 10))
for i, col in enumerate(numerical_cols):
    plt.subplot(3, 2, i + 1)
    sns.histplot(data[col], kde=True)
    plt.title(f'Distribution of {col}')
plt.tight_layout()
plt.show()

# Box plots
plt.figure(figsize=(15, 10))
for i, col in enumerate(numerical_cols):
    plt.subplot(3, 2, i + 1)
    sns.boxplot(x=data[col])
    plt.title(f'Box Plot of {col}')
plt.tight_layout()
plt.show()

# Summary statistics
print("\nSummary Statistics for Numerical Columns:")
for col in numerical_cols:
    print(f"{col}:")
    print(f"  Mean: {data[col].mean():.2f}")
    print(f"  Median: {data[col].median():.2f}")
    print(f"  Standard Deviation: {data[col].std():.2f}")
    print("-" * 20)

categorical_cols = ['jenis_kelamin', 'jenis_produk', 'pengguna_mobile_banking']

print("\nFrequency Counts for Categorical Columns:")
for col in categorical_cols:
    print(f"\n{col}:")
    print(data[col].value_counts())

"""## Validasi konsistensi data (jika relevan)

### Subtask:
Periksa konsistensi antar kolom atau dalam format data jika ada aturan bisnis atau batasan tertentu yang harus dipenuhi (misalnya, rentang usia yang valid, format tanggal, dll. - Pada dataset ini mungkin tidak banyak aturan konsistensi yang jelas antar kolom, tapi kita akan tetap periksa distribusi untuk melihat hal yang tidak biasa).

**Reasoning**:
Review the descriptive statistics and frequency counts from the previous steps to check for any values outside expected ranges or unexpected categories. Document any inconsistencies or unusual patterns found based on a general understanding of typical customer data.
"""

# Reviewing descriptive statistics for numerical columns
print("Review of Numerical Column Ranges:")
numerical_summary = data[numerical_cols].describe()
print(numerical_summary)

# Check for unexpected ranges (based on general assumptions)
# Umur: Should be a reasonable age for a bank customer, typically > 18. Min is 20, Max is 64 - seems reasonable.
# Pendapatan: Values seem plausible for income levels.
# Saldo_rata_rata: Values seem plausible for account balances.
# Jumlah_transaksi: Values seem plausible for transaction counts.
# Frekuensi_kunjungi_cabang: Values seem plausible for visit frequency.
# Skor_kredit: Values are within a typical credit score range (e.g., 500-900 in this case).

print("\nReview of Categorical Column Values:")
categorical_counts = {}
for col in categorical_cols:
    categorical_counts[col] = data[col].value_counts()
    print(f"\n{col}:")
    print(categorical_counts[col])

# Check for unexpected categories (based on previous mapping)
# jenis_kelamin: Expected values after mapping are 1 and 2. Counts show only 1 and 2. Consistent.
# jenis_produk: Expected values after mapping are 1, 2, and 3. Counts show only 1, 2, and 3. Consistent.
# pengguna_mobile_banking: Expected values after mapping are 1 and 2. Counts show only 1 and 2. Consistent.

print("\nConsistency Check Summary:")
print("- Numerical column ranges appear reasonable based on general assumptions.")
print("- Categorical column values match the expected categories after encoding.")
print("- No obvious inconsistencies between related columns found by simply reviewing descriptive statistics and value counts.")
print("  (Deeper relationship analysis was covered in bivariate/multivariate steps)")

print("\nAny inconsistencies or unusual patterns found:")
print("- No significant inconsistencies or unusual patterns were identified based on the review of descriptive statistics and value counts against general expectations.")

"""## Ringkasan temuan validasi data

### Subtask:
Sajikan temuan-temuan kunci dari proses validasi data, termasuk masalah kualitas data yang ditemukan dan tindakan yang diambil.

**Reasoning**:
Summarize the key findings from the data validation process, including dataset characteristics, missing values, duplicates, univariate analysis observations, and consistency checks, and explicitly state any data quality issues found and actions taken.
"""

print("## Ringkasan Temuan Validasi Data")

print("\n### 1. Karakteristik Dataset")
print("- Dataset terdiri dari 100 baris dan 10 kolom.")
print("- Tipe data meliputi numerik (int64) dan kategorikal (object yang sudah di-encode).")

print("\n### 2. Validasi Kelengkapan Data")
print("- Tidak ditemukan adanya nilai yang hilang (missing values) pada setiap kolom data.")

print("\n### 3. Validasi Keunikan Data")
print("- Tidak ditemukan adanya baris yang terduplikasi dalam dataset.")

print("\n### 4. Validasi Distribusi Data (Univariat)")
print("- Distribusi variabel numerik bervariasi, dengan beberapa variabel ('pendapatan', 'saldo_rata_rata') menunjukkan potensi adanya outlier berdasarkan visualisasi box plot.")
print("- Distribusi variabel kategorikal ('jenis_kelamin', 'jenis_produk', 'pengguna_mobile_banking') menunjukkan sebaran frekuensi yang dapat diterima antar kategori yang ada.")

print("\n### 5. Validasi Konsistensi Data")
print("- Rentang nilai pada kolom numerik ('umur', 'pendapatan', 'saldo_rata_rata', 'jumlah_transaksi', 'frekuensi_kunjungi_cabang', 'skor_kredit') terlihat wajar berdasarkan asumsi umum.")
print("- Nilai pada kolom kategorikal ('jenis_kelamin', 'jenis_produk', 'pengguna_mobile_banking') konsisten dengan kategori yang diharapkan setelah proses encoding.")
print("- Tidak ditemukan inkonsistensi yang jelas antar kolom berdasarkan tinjauan statistik deskriptif dan hitungan frekuensi.")

print("\n### 6. Isu Kualitas Data dan Tindakan yang Diambil")
print("- **Isu:** Potensi adanya outlier teridentifikasi pada beberapa variabel numerik ('pendapatan', 'saldo_rata_rata') melalui analisis univariat (box plot).")
print("- **Tindakan:** Pada tahap validasi ini, outlier dicatat sebagai temuan. Penanganan lebih lanjut (misalnya, investigasi, transformasi, atau penghapusan) akan dipertimbangkan pada tahap analisis atau pemodelan selanjutnya jika diperlukan.")
print("- **Isu:** Tidak ada missing values atau duplicate rows.")
print("- **Tindakan:** Tidak ada tindakan yang diperlukan untuk missing values atau duplicate rows karena tidak ada yang ditemukan.")

print("\n### Kesimpulan Validasi Data")
print("Berdasarkan proses validasi yang telah dilakukan, dataset 'Data_Nasabah.csv' memiliki kualitas data yang baik.")
print("Tidak ada missing values atau duplicate rows yang ditemukan. Distribusi data terlihat wajar, meskipun ada potensi outlier pada beberapa variabel numerik yang perlu dicatat untuk analisis selanjutnya.")
print("Data ini siap untuk tahap eksplorasi dan analisis lebih lanjut.")

"""## Summary:

### Data Analysis Key Findings

*   The dataset contains 100 rows and 10 columns, with a mix of numerical (`int64`) and encoded categorical (`object`) data types.
*   There are no missing values or duplicate rows in the dataset.
*   Univariate analysis revealed that while most numerical columns have expected distributions, potential outliers were identified in the 'pendapatan' (income) and 'saldo\_rata\_rata' (average balance) columns based on box plot visualizations.
*   Categorical columns ('jenis\_kelamin', 'jenis\_produk', 'pengguna\_mobile\_banking') show consistent values matching the expected categories after encoding.
*   Numerical column ranges appear reasonable, and no obvious inconsistencies between columns were found based on descriptive statistics and frequency counts.

### Insights or Next Steps

*   The dataset is generally of good quality, lacking missing values and duplicates, making it ready for further analysis.
*   Further investigation or specific handling strategies for the potential outliers in 'pendapatan' and 'saldo\_rata\_rata' should be considered during subsequent analysis or modeling phases if their impact is deemed significant.

# Task
Lakukan eksplorasi lebih lanjut pada dataset yang sedang digunakan, termasuk segmentasi pelanggan (clustering), analisis pengaruh variabel kategorikal terhadap variabel numerik, dan analisis outlier.

## Segmentasi pelanggan (clustering)

### Subtask:
Gunakan algoritma clustering seperti K-Means untuk mengidentifikasi segmen nasabah berdasarkan variabel numerik.

**Reasoning**:
Select numerical columns, standardize the data, and determine the optimal number of clusters using the elbow method by calculating inertia for different k values and plotting the results to visualize the elbow point.
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt

# Load the data again
# Make sure the file path is correct for your environment
try:
    data = pd.read_csv('/content/drive/MyDrive/datanasabah.csv')
except FileNotFoundError:
    print("Error: Make sure the file path is correct and Google Drive is mounted.")
    # If the file is not found, we cannot proceed.
    exit() # Exit the cell execution if file not found

# Perform the encoding again
data['jenis_kelamin'] = data['jenis_kelamin'].map({'Laki-Laki': 1, 'Perempuan': 2})
data['jenis_produk'] = data['jenis_produk'].map({'tabungan': 1, 'kartu_kredit': 2, 'deposito': 3})
data['pengguna_mobile_banking'] = data['pengguna_mobile_banking'].map({'YA': 1, 'TIDAK': 2})


numerical_cols = ['umur', 'pendapatan', 'saldo_rata_rata', 'jumlah_transaksi', 'frekuensi_kunjungi_cabang', 'skor_kredit']
numerical_data = data[numerical_cols]

# Standardize the numerical data
scaler = StandardScaler()
scaled_numerical_data = scaler.fit_transform(numerical_data)

# Determine the optimal number of clusters using the elbow method
inertia = []
k_range = range(1, 11)
for k in k_range:
    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
    kmeans.fit(scaled_numerical_data)
    inertia.append(kmeans.inertia_)

# Plot the elbow method graph
plt.figure(figsize=(8, 5))
plt.plot(k_range, inertia, marker='o')
plt.title('Elbow Method for Optimal k')
plt.xlabel('Number of Clusters (k)')
plt.ylabel('Inertia')
plt.xticks(k_range)
plt.grid(True)
plt.show()

# Based on the elbow plot, choose an appropriate number of clusters (let's assume k=3 for demonstration)
# You would visually inspect the plot and choose the 'elbow' point.
optimal_k = 3

# Apply K-Means with the chosen number of clusters
kmeans_final = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)
cluster_labels = kmeans_final.fit_predict(scaled_numerical_data)

# Add the cluster labels to the original DataFrame
data['cluster_label'] = cluster_labels

# Print the value counts of the cluster labels
print("\nNumber of customers in each cluster:")
print(data['cluster_label'].value_counts())

"""**Reasoning**:
The previous code failed because the DataFrame `data` was not available in the current session. I need to reload the data and perform the same steps again to determine the optimal number of clusters using the elbow method. I will also include the steps to apply K-Means with the chosen number of clusters and add the cluster labels to the DataFrame, and then print the value counts of the cluster labels, to complete the subtask in a single code block.


"""

import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt

# Load the data again
data = pd.read_csv('/content/drive/MyDrive/datanasabah.csv')

# Perform the encoding again
data['jenis_kelamin'] = data['jenis_kelamin'].map({'Laki-Laki': 1, 'Perempuan': 2})
data['jenis_produk'] = data['jenis_produk'].map({'tabungan': 1, 'kartu_kredit': 2, 'deposito': 3})
data['pengguna_mobile_banking'] = data['pengguna_mobile_banking'].map({'YA': 1, 'TIDAK': 2})

# Select numerical columns
numerical_cols = ['umur', 'pendapatan', 'saldo_rata_rata', 'jumlah_transaksi', 'frekuensi_kunjungi_cabang', 'skor_kredit']
numerical_data = data[numerical_cols]

# Standardize the numerical data
scaler = StandardScaler()
scaled_numerical_data = scaler.fit_transform(numerical_data)

# Determine the optimal number of clusters using the elbow method
inertia = []
k_range = range(1, 11)
for k in k_range:
    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
    kmeans.fit(scaled_numerical_data)
    inertia.append(kmeans.inertia_)

# Plot the elbow method graph
plt.figure(figsize=(8, 5))
plt.plot(k_range, inertia, marker='o')
plt.title('Elbow Method for Optimal k')
plt.xlabel('Number of Clusters (k)')
plt.ylabel('Inertia')
plt.xticks(k_range)
plt.grid(True)
plt.show()

# Based on the elbow plot, choose an appropriate number of clusters (let's assume k=3 for demonstration)
# You would visually inspect the plot and choose the 'elbow' point.
optimal_k = 3

# Apply K-Means with the chosen number of clusters
kmeans_final = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)
cluster_labels = kmeans_final.fit_predict(scaled_numerical_data)

# Add the cluster labels to the original DataFrame
data['cluster_label'] = cluster_labels

# Print the value counts of the cluster labels
print("\nNumber of customers in each cluster:")
print(data['cluster_label'].value_counts())

"""**Reasoning**:
The previous code failed because the file path to the dataset was incorrect or the drive was not mounted properly in the new session. I will try to load the data again, ensuring the correct path is used, and then proceed with the clustering steps as outlined in the subtask.


"""

import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt

# Load the data again, assuming the path is correct now
try:
    data = pd.read_csv('/content/drive/MyDrive/datanasabah.csv')
except FileNotFoundError:
    print("Error: Make sure the file path is correct and Google Drive is mounted.")
    # If the file is not found, we cannot proceed. I will finish the task with failure.
    # In a real scenario, I might try to re-mount or ask the user for the correct path,
    # but based on the instructions, I should just report failure if I cannot proceed.
    raise # Re-raise the exception to indicate failure


# Perform the encoding again
data['jenis_kelamin'] = data['jenis_kelamin'].map({'Laki-Laki': 1, 'Perempuan': 2})
data['jenis_produk'] = data['jenis_produk'].map({'tabungan': 1, 'kartu_kredit': 2, 'deposito': 3})
data['pengguna_mobile_banking'] = data['pengguna_mobile_banking'].map({'YA': 1, 'TIDAK': 2})

# Select numerical columns
numerical_cols = ['umur', 'pendapatan', 'saldo_rata_rata', 'jumlah_transaksi', 'frekuensi_kunjungi_cabang', 'skor_kredit']
numerical_data = data[numerical_cols]

# Standardize the numerical data
scaler = StandardScaler()
scaled_numerical_data = scaler.fit_transform(numerical_data)

# Determine the optimal number of clusters using the elbow method
inertia = []
k_range = range(1, 11)
for k in k_range:
    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
    kmeans.fit(scaled_numerical_data)
    inertia.append(kmeans.inertia_)

# Plot the elbow method graph
plt.figure(figsize=(8, 5))
plt.plot(k_range, inertia, marker='o')
plt.title('Elbow Method for Optimal k')
plt.xlabel('Number of Clusters (k)')
plt.ylabel('Inertia')
plt.xticks(k_range)
plt.grid(True)
plt.show()

# Based on the elbow plot, choose an appropriate number of clusters (let's assume k=3 for demonstration)
# You would visually inspect the plot and choose the 'elbow' point.
optimal_k = 3

# Apply K-Means with the chosen number of clusters
kmeans_final = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)
cluster_labels = kmeans_final.fit_predict(scaled_numerical_data)

# Add the cluster labels to the original DataFrame
data['cluster_label'] = cluster_labels

# Print the value counts of the cluster labels
print("\nNumber of customers in each cluster:")
print(data['cluster_label'].value_counts())

"""## Analisis Pengaruh Variabel Kategorikal terhadap Numerik

### Subtask:
Lakukan uji statistik (misalnya T-Test atau ANOVA) untuk membandingkan rata-rata variabel numerik antar kelompok dalam variabel kategorikal.
"""

from scipy import stats
import statsmodels.api as sm
from statsmodels.formula.api import ols
import warnings

# Suppress potential warnings from statsmodels
warnings.filterwarnings("ignore")

numerical_cols = ['umur', 'pendapatan', 'saldo_rata_rata', 'jumlah_transaksi', 'frekuensi_kunjungi_cabang', 'skor_kredit']
categorical_cols = ['jenis_kelamin', 'jenis_produk', 'pengguna_mobile_banking']

print("### Analisis Pengaruh Variabel Kategorikal terhadap Numerik")

# Perform statistical tests
for cat_col in categorical_cols:
    print(f"\n--- Analisis berdasarkan '{cat_col}' ---")
    unique_categories = data[cat_col].unique()

    if len(unique_categories) == 2: # T-test for two categories
        print(f"Melakukan Independent Samples T-test untuk '{cat_col}'")
        group1 = data[data[cat_col] == unique_categories[0]]
        group2 = data[data[cat_col] == unique_categories[1]]

        for num_col in numerical_cols:
            # Check if groups have enough data points for t-test
            if len(group1[num_col]) > 1 and len(group2[num_col]) > 1:
                t_stat, p_value = stats.ttest_ind(group1[num_col], group2[num_col], nan_policy='omit')
                print(f"  - {num_col}: T-statistic = {t_stat:.4f}, P-value = {p_value:.4f}")
                if p_value < 0.05:
                    print("    (Perbedaan rata-rata signifikan secara statistik)")
                else:
                    print("    (Tidak ada perbedaan rata-rata yang signifikan secara statistik)")
            else:
                print(f"  - {num_col}: Tidak cukup data di salah satu atau kedua grup untuk T-test.")

    elif len(unique_categories) > 2: # ANOVA for more than two categories
        print(f"Melakukan One-Way ANOVA untuk '{cat_col}'")
        for num_col in numerical_cols:
            # Prepare data for ANOVA (list of arrays/series for each group)
            groups_data = [data[data[cat_col] == cat][num_col].dropna() for cat in unique_categories]

            # Check if all groups have at least one data point
            if all(len(group) > 0 for group in groups_data):
                 # Check if there is more than one group with data
                if len(groups_data) > 1:
                    f_stat, p_value = stats.f_oneway(*groups_data)
                    print(f"  - {num_col}: F-statistic = {f_stat:.4f}, P-value = {p_value:.4f}")
                    if p_value < 0.05:
                        print("    (Perbedaan rata-rata signifikan secara statistik)")
                    else:
                        print("    (Tidak ada perbedaan rata-rata yang signifikan secara statistik)")
                else:
                    print(f"  - {num_col}: Hanya ada satu grup dengan data untuk ANOVA.")
            else:
                 print(f"  - {num_col}: Tidak cukup data di beberapa grup untuk ANOVA.")

    else:
        print(f"  - Kolom '{cat_col}' memiliki kurang dari dua kategori unik. Tidak dapat melakukan T-test atau ANOVA.")

print("\nAnalisis Uji Statistik Selesai.")

"""## Analisis Outlier

### Subtask:
Identifikasi dan analisis outlier pada variabel numerik menggunakan metode statistik.
"""

import numpy as np

numerical_cols = ['umur', 'pendapatan', 'saldo_rata_rata', 'jumlah_transaksi', 'frekuensi_kunjungi_cabang', 'skor_kredit']

print("### Analisis Outlier (Menggunakan Metode IQR)")

outlier_info = {}

for col in numerical_cols:
    Q1 = data[col].quantile(0.25)
    Q3 = data[col].quantile(0.75)
    IQR = Q3 - Q1

    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR

    outliers = data[(data[col] < lower_bound) | (data[col] > upper_bound)]

    print(f"\n--- Kolom '{col}' ---")
    print(f"  Q1 (25th percentile): {Q1:.2f}")
    print(f"  Q3 (75th percentile): {Q3:.2f}")
    print(f"  IQR (Interquartile Range): {IQR:.2f}")
    print(f"  Lower Bound: {lower_bound:.2f}")
    print(f"  Upper Bound: {upper_bound:.2f}")
    print(f"  Jumlah Outlier: {len(outliers)}")

    if len(outliers) > 0:
        print("  Data Outlier (beberapa contoh):")
        display(outliers.head())
    else:
        print("  Tidak ada outlier yang teridentifikasi menggunakan metode IQR.")

    outlier_info[col] = {
        'Q1': Q1,
        'Q3': Q3,
        'IQR': IQR,
        'lower_bound': lower_bound,
        'upper_bound': upper_bound,
        'num_outliers': len(outliers),
        'outlier_data': outliers
    }

print("\nAnalisis Outlier Selesai.")

"""## Ringkasan Temuan Tambahan

### Subtask:
Sajikan temuan-temuan kunci dari eksplorasi lebih lanjut ini.
"""

print("## Ringkasan Temuan Eksplorasi Data Tambahan")

print("\n### 1. Segmentasi Pelanggan (Clustering)")
print("- Menggunakan metode Elbow pada K-Means, kami memilih jumlah cluster optimal (berdasarkan visualisasi). Dalam contoh ini, kita menggunakan k=3.")
print(f"- Dataset dibagi menjadi {data['cluster_label'].nunique()} cluster.")
print("- Jumlah nasabah di setiap cluster:")
print(data['cluster_label'].value_counts())
print("- Untuk pemahaman yang lebih mendalam tentang karakteristik setiap cluster, diperlukan analisis profil cluster (misalnya, melihat rata-rata variabel di setiap cluster).")

print("\n### 2. Analisis Pengaruh Variabel Kategorikal terhadap Numerik")
print("- **Jenis Kelamin:** Uji T-test menunjukkan tidak ada perbedaan rata-rata yang signifikan secara statistik pada variabel numerik ('umur', 'pendapatan', 'saldo_rata_rata', 'jumlah_transaksi', 'frekuensi_kunjungi_cabang', 'skor_kredit') antara kelompok jenis kelamin.")
print("- **Jenis Produk:** Uji One-Way ANOVA menunjukkan adanya perbedaan rata-rata yang signifikan secara statistik hanya pada variabel 'frekuensi_kunjungi_cabang' antar kelompok jenis produk. Untuk variabel numerik lainnya, tidak ada perbedaan rata-rata yang signifikan secara statistik berdasarkan jenis produk.")
print("- **Pengguna Mobile Banking:** Uji T-test menunjukkan tidak ada perbedaan rata-rata yang signifikan secara statistik pada variabel numerik ('umur', 'pendapatan', 'saldo_rata_rata', 'jumlah_transaksi', 'frekuensi_kunjungi_cabang', 'skor_kredit') antara kelompok pengguna dan non-pengguna mobile banking.")

print("\n### 3. Analisis Outlier (Menggunakan Metode IQR)")
print("- Variabel 'saldo_rata_rata' teridentifikasi memiliki 1 outlier menggunakan metode IQR.")
print("- Variabel numerik lainnya ('umur', 'pendapatan', 'jumlah_transaksi', 'frekuensi_kunjungi_cabang', 'skor_kredit') tidak menunjukkan adanya outlier berdasarkan metode IQR.")
print("- Keberadaan outlier tunggal pada 'saldo_rata_rata' mungkin perlu diinvestigasi lebih lanjut, namun dampaknya terhadap analisis secara keseluruhan kemungkinan kecil.")

print("\n### Kesimpulan Tambahan")
print("Eksplorasi lebih lanjut ini memberikan wawasan tambahan mengenai dataset:")
print("- Segmentasi awal menghasilkan 3 cluster yang perlu dianalisis profilnya lebih lanjut.")
print("- 'Jenis Produk' memiliki pengaruh signifikan terhadap 'frekuensi_kunjungi_cabang', sementara variabel kategorikal lainnya tidak menunjukkan pengaruh signifikan terhadap rata-rata variabel numerik yang diuji.")
print("- Hanya satu outlier yang teridentifikasi pada 'saldo_rata_rata'.")

"""# Task
Lakukan eksplorasi lebih lanjut pada dataset untuk menganalisis hubungan antara 'jenis produk' dan 'frekuensi kunjungi cabang'.

## Visualisasi hubungan

### Subtask:
Buat visualisasi yang jelas untuk menunjukkan hubungan antara 'jenis produk' dan 'frekuensi kunjungi cabang'.

**Reasoning**:
Generate a box plot to visualize the relationship between 'jenis_produk' and 'frekuensi_kunjungi_cabang' as requested by the subtask instructions.
"""

import matplotlib.pyplot as plt
import seaborn as sns

# Create a box plot
plt.figure(figsize=(8, 6))
sns.boxplot(x='jenis_produk', y='frekuensi_kunjungi_cabang', data=data)

# Add title and labels
plt.title('Hubungan antara Jenis Produk dan Frekuensi Kunjungi Cabang')
plt.xlabel('Jenis Produk')
plt.ylabel('Frekuensi Kunjungi Cabang')

# Show the plot
plt.show()

"""## Analisis deskriptif

### Subtask:
Hitung rata-rata atau median 'frekuensi kunjungi cabang' untuk setiap kategori 'jenis produk' untuk memahami perbedaannya secara kuantitatif.

**Reasoning**:
Calculate and print the mean and median of 'frekuensi_kunjungi_cabang' for each category of 'jenis_produk'.
"""

# Calculate the mean 'frekuensi_kunjungi_cabang' for each 'jenis_produk'
mean_frequency_by_product = data.groupby('jenis_produk')['frekuensi_kunjungi_cabang'].mean()

# Calculate the median 'frekuensi_kunjungi_cabang' for each 'jenis_produk'
median_frequency_by_product = data.groupby('jenis_produk')['frekuensi_kunjungi_cabang'].median()

print("Mean 'frekuensi_kunjungi_cabang' by 'jenis_produk':")
print(mean_frequency_by_product)

print("\nMedian 'frekuensi_kunjungi_cabang' by 'jenis_produk':")
print(median_frequency_by_product)

"""## Ringkasan temuan

### Subtask:
Sajikan temuan kunci dari eksplorasi spesifik ini.

**Reasoning**:
Summarize the key findings from the previous visualization and descriptive analysis steps to present the relationship between 'jenis produk' and 'frekuensi kunjungi cabang'.
"""

print("## Ringkasan Temuan: Hubungan antara Jenis Produk dan Frekuensi Kunjungi Cabang")

print("\n### 1. Temuan dari Visualisasi (Box Plot)")
print("- Box plot menunjukkan distribusi 'frekuensi_kunjungi_cabang' untuk setiap 'jenis_produk'.")
print("- Terlihat bahwa 'jenis_produk' dengan kode 3 (deposito) cenderung memiliki frekuensi kunjungan cabang yang lebih tinggi dibandingkan dengan 'jenis_produk' dengan kode 1 (tabungan) dan 2 (kartu_kredit).")
print("- Sebaran (interquartile range) frekuensi kunjungan juga bervariasi antar jenis produk.")

print("\n### 2. Temuan dari Analisis Deskriptif (Rata-rata dan Median)")
print("- Rata-rata frekuensi kunjungan cabang untuk 'jenis_produk' 1 (tabungan) adalah sekitar {:.2f}.".format(mean_frequency_by_product[1]))
print("- Rata-rata frekuensi kunjungan cabang untuk 'jenis_produk' 2 (kartu_kredit) adalah sekitar {:.2f}.".format(mean_frequency_by_product[2]))
print("- Rata-rata frekuensi kunjungan cabang untuk 'jenis_produk' 3 (deposito) adalah sekitar {:.2f}.".format(mean_frequency_by_product[3]))
print("- Median frekuensi kunjungan cabang untuk 'jenis_produk' 1 (tabungan) adalah {:.1f}.".format(median_frequency_by_product[1]))
print("- Median frekuensi kunjungan cabang untuk 'jenis_produk' 2 (kartu_kredit) adalah {:.1f}.".format(median_frequency_by_product[2])) # Corrected variable name
print("- Median frekuensi kunjungan cabang untuk 'jenis_produk' 3 (deposito) adalah {:.1f}.".format(median_frequency_by_product[3]))
print("- Angka rata-rata dan median ini secara kuantitatif mendukung temuan dari visualisasi, di mana jenis produk 3 (deposito) memiliki nilai rata-rata dan median frekuensi kunjungan cabang tertinggi.")

print("\n### 3. Kesimpulan Hubungan")
print("Berdasarkan visualisasi box plot dan analisis deskriptif (rata-rata dan median), terdapat indikasi kuat bahwa jenis produk yang dimiliki nasabah memiliki hubungan dengan seberapa sering mereka mengunjungi cabang.")
print("Nasabah dengan produk deposito (jenis_produk = 3) cenderung mengunjungi cabang lebih sering dibandingkan nasabah dengan produk tabungan atau kartu kredit.")
print("Temuan ini signifikan secara statistik, sebagaimana ditunjukkan pada analisis pengaruh variabel kategorikal terhadap numerik sebelumnya (ANOVA untuk 'jenis_produk' dan 'frekuensi_kunjungi_cabang' menghasilkan p-value < 0.05).")

print("\nEksplorasi spesifik ini selesai.")

"""**Reasoning**:
The previous code failed due to a `NameError` because `median_frequency_by_branch` was used instead of `median_frequency_by_product`. I need to correct this typo and regenerate the summary findings.


"""

print("## Ringkasan Temuan: Hubungan antara Jenis Produk dan Frekuensi Kunjungi Cabang")

print("\n### 1. Temuan dari Visualisasi (Box Plot)")
print("- Box plot menunjukkan distribusi 'frekuensi_kunjungi_cabang' untuk setiap 'jenis_produk'.")
print("- Terlihat bahwa 'jenis_produk' dengan kode 3 (deposito) cenderung memiliki frekuensi kunjungan cabang yang lebih tinggi dibandingkan dengan 'jenis_produk' dengan kode 1 (tabungan) dan 2 (kartu_kredit).")
print("- Sebaran (interquartile range) frekuensi kunjungan juga bervariasi antar jenis produk.")

print("\n### 2. Temuan dari Analisis Deskriptif (Rata-rata dan Median)")
print("- Rata-rata frekuensi kunjungan cabang untuk 'jenis_produk' 1 (tabungan) adalah sekitar {:.2f}.".format(mean_frequency_by_product[1]))
print("- Rata-rata frekuensi kunjungan cabang untuk 'jenis_produk' 2 (kartu_kredit) adalah sekitar {:.2f}.".format(mean_frequency_by_product[2]))
print("- Rata-rata frekuensi kunjungan cabang untuk 'jenis_produk' 3 (deposito) adalah sekitar {:.2f}.".format(mean_frequency_by_product[3]))
print("- Median frekuensi kunjungan cabang untuk 'jenis_produk' 1 (tabungan) adalah {:.1f}.".format(median_frequency_by_product[1]))
print("- Median frekuensi kunjungan cabang untuk 'jenis_produk' 2 (kartu_kredit) adalah {:.1f}.".format(median_frequency_by_product[2])) # Corrected variable name
print("- Median frekuensi kunjungan cabang untuk 'jenis_produk' 3 (deposito) adalah {:.1f}.".format(median_frequency_by_product[3]))
print("- Angka rata-rata dan median ini secara kuantitatif mendukung temuan dari visualisasi, di mana jenis produk 3 (deposito) memiliki nilai rata-rata dan median frekuensi kunjungan cabang tertinggi.")

print("\n### 3. Kesimpulan Hubungan")
print("Berdasarkan visualisasi box plot dan analisis deskriptif (rata-rata dan median), terdapat indikasi kuat bahwa jenis produk yang dimiliki nasabah memiliki hubungan dengan seberapa sering mereka mengunjungi cabang.")
print("Nasabah dengan produk deposito (jenis_produk = 3) cenderung mengunjungi cabang lebih sering dibandingkan nasabah dengan produk tabungan atau kartu kredit.")
print("Temuan ini signifikan secara statistik, sebagaimana ditunjukkan pada analisis pengaruh variabel kategorikal terhadap numerik sebelumnya (ANOVA untuk 'jenis_produk' dan 'frekuensi_kunjungi_cabang' menghasilkan p-value < 0.05).")

print("\nEksplorasi spesifik ini selesai.")

"""## Summary:

### Data Analysis Key Findings

*   Product type 3 (deposito) is associated with a higher average (approx. 3.33) and median (3.0) frequency of branch visits compared to product type 1 (tabungan) with an average of approx. 2.48 and median of 2.0, and product type 2 (kartu\_kredit) with an average of approx. 2.31 and median of 2.0.
*   The box plot visualization supports these findings, showing that the distribution of branch visit frequency for product type 3 is shifted towards higher values.

### Insights or Next Steps

*   Investigate the specific needs or reasons why customers with deposito products require more frequent branch visits.
*   Explore opportunities to potentially reduce the need for frequent branch visits for deposito holders through digital channels or alternative service methods, if feasible and beneficial.

"""

# Save the DataFrame to a CSV file
csv_file_path = '/content/data_nasabah_explored.csv'
data.to_csv(csv_file_path, index=False)

print(f"Dataframe berhasil disimpan ke: {csv_file_path}")