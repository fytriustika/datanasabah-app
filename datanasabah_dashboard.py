# -*- coding: utf-8 -*-
"""datanasabah-dashboard.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1u93KHsd4N3eUsSFNt9G54uf6ADKjfkw1
"""

# app.py
import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from io import StringIO

from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.cluster import KMeans
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.metrics import mean_squared_error, r2_score
from scipy import stats

st.set_option('deprecation.showPyplotGlobalUse', False)
sns.set(style="whitegrid")

# -------------------------
# Helper functions
# -------------------------
@st.cache_data
def load_data(csv_file):
    df = pd.read_csv(csv_file)
    return df

@st.cache_data
def encode_df(df):
    df = df.copy()
    # encoding as in your notebook
    df['jenis_kelamin'] = df['jenis_kelamin'].map({'Laki-Laki': 1, 'Perempuan': 2})
    df['jenis_produk'] = df['jenis_produk'].map({'tabungan': 1, 'kartu_kredit': 2, 'deposito': 3})
    df['pengguna_mobile_banking'] = df['pengguna_mobile_banking'].map({'YA': 1, 'TIDAK': 2})
    return df

@st.cache_data
def basic_stats(df):
    numeric = df.select_dtypes(include=[np.number])
    return df.shape, df.dtypes, numeric.describe(include='all'), df.isnull().sum()

def plot_histograms(df, cols):
    n = len(cols)
    rows = int(np.ceil(n/2))
    plt.figure(figsize=(10, 4*rows))
    for i, c in enumerate(cols, 1):
        plt.subplot(rows, 2, i)
        sns.histplot(df[c].dropna(), kde=True)
        plt.title(f'Distribution: {c}')
    plt.tight_layout()
    st.pyplot()

def plot_boxplots(df, cols):
    n = len(cols)
    rows = int(np.ceil(n/2))
    plt.figure(figsize=(10, 4*rows))
    for i, c in enumerate(cols, 1):
        plt.subplot(rows, 2, i)
        sns.boxplot(x=df[c].dropna())
        plt.title(f'Boxplot: {c}')
    plt.tight_layout()
    st.pyplot()

def corr_heatmap(df, cols):
    cm = df[cols].corr()
    plt.figure(figsize=(8,6))
    sns.heatmap(cm, annot=True, cmap='coolwarm', fmt='.2f')
    st.pyplot()
    return cm

@st.cache_data
def run_pca(df, cols):
    scaler = StandardScaler()
    Xs = scaler.fit_transform(df[cols])
    pca = PCA(n_components=min(len(cols), 6))
    pcs = pca.fit_transform(Xs)
    pc_df = pd.DataFrame(pcs, columns=[f'PC{i+1}' for i in range(pcs.shape[1])])
    return pca, pc_df

@st.cache_data
def kmeans_with_elbow(df, cols, kmax=8):
    scaler = StandardScaler()
    Xs = scaler.fit_transform(df[cols])
    inertias = []
    for k in range(1, kmax+1):
        km = KMeans(n_clusters=k, random_state=42, n_init=10)
        km.fit(Xs)
        inertias.append(km.inertia_)
    # default chosen k = 3 (as in your notebook)
    chosen_k = 3
    km_final = KMeans(n_clusters=chosen_k, random_state=42, n_init=10).fit(Xs)
    labels = km_final.labels_
    return inertias, chosen_k, labels

def train_and_eval_regressors(X_train, X_test, y_train, y_test):
    models = {
        "Linear Regression": LinearRegression(),
        "Decision Tree": DecisionTreeRegressor(random_state=42),
        "Random Forest": RandomForestRegressor(random_state=42),
        "Gradient Boosting": GradientBoostingRegressor(random_state=42)
    }
    results = {}
    for name, m in models.items():
        m.fit(X_train, y_train)
        pred = m.predict(X_test)
        mse = mean_squared_error(y_test, pred)
        rmse = np.sqrt(mse)
        r2 = r2_score(y_test, pred)
        results[name] = {"model": m, "MSE": mse, "RMSE": rmse, "R2": r2}
    return results

# -------------------------
# UI
# -------------------------
st.title("Customer Data Dashboard — Datanasabah")
st.markdown("A Streamlit dashboard reproducing analyses and findings from the provided notebook. "
            "It includes EDA, clustering, modeling and narrative conclusions embedded next to visuals.")

# Data upload / load
st.sidebar.header("Data input")
uploaded = st.sidebar.file_uploader("Upload datanasabah.csv (if not present in session)", type=['csv'])
if uploaded is not None:
    df_raw = load_data(uploaded)
else:
    # default path (if running in same folder)
    try:
        df_raw = load_data('datanasabah.csv')
    except Exception as e:
        st.error("No CSV found. Please upload `datanasabah.csv` via the sidebar.")
        st.stop()

st.sidebar.markdown("Preview & settings")
show_preview = st.sidebar.checkbox("Show raw data preview", value=True)

if show_preview:
    st.subheader("Raw data (first 10 rows)")
    st.dataframe(df_raw.head(10))

# Preprocess / encode
df = encode_df(df_raw)

# Overview
st.header("Overview & Data Validation")
shape, dtypes, desc, missing = basic_stats(df)
st.write(f"Shape: {shape[0]} rows × {shape[1]} columns")
st.write("Column types:")
st.write(dtypes)
st.write("Missing values per column:")
st.write(missing)

st.markdown("**Notebook finding (summary):** the notebook reported there were *no missing values* and no duplicate rows; general distributions were reasonable. :contentReference[oaicite:2]{index=2}")

# Univariat EDA
st.header("Univariate Analysis")
numerical_cols = ['umur', 'pendapatan', 'saldo_rata_rata', 'jumlah_transaksi', 'frekuensi_kunjungi_cabang', 'skor_kredit']
plot_histograms(df, numerical_cols)
plot_boxplots(df, numerical_cols)

# Bivariate
st.header("Bivariate Analysis")
st.markdown("Scatter pairwise plots and correlation heatmap for numerical features.")
if st.button("Show correlation heatmap"):
    cm = corr_heatmap(df, numerical_cols)
    st.write("Correlation matrix:")
    st.dataframe(cm)

st.markdown("**Notebook finding:** the notebook observed a notable positive correlation between `pendapatan` and `saldo_rata_rata` (around 0.61 in the notebook) and used this in commentary. :contentReference[oaicite:3]{index=3}")

# Pairplot (PCA)
st.header("PCA & Pair Plot")
pca, pc_df = run_pca(df, numerical_cols)
st.write("Explained variance ratio (per component):")
st.write(np.round(pca.explained_variance_ratio_, 4))
st.markdown("Notebook noted ~48.96% explained by PC1+PC2 in its run and observed limited cluster separation visually. :contentReference[oaicite:4]{index=4}")
fig, ax = plt.subplots()
sns.scatterplot(x=pc_df['PC1'], y=pc_df['PC2'], hue=df['jenis_produk'].astype(str), palette='tab10', ax=ax)
ax.set_title("PC1 vs PC2 colored by jenis_produk")
st.pyplot(fig)

# Clustering
st.header("Customer Segmentation (K-Means)")
st.markdown("Elbow plot (inertia) and chosen k=3 by default (as in your notebook).")
inertias, chosen_k, labels = kmeans_with_elbow(df, numerical_cols, kmax=8)
fig, ax = plt.subplots()
ax.plot(range(1, len(inertias)+1), inertias, marker='o')
ax.set_xlabel('k')
ax.set_ylabel('Inertia')
ax.set_title('Elbow Plot')
st.pyplot(fig)

st.write(f"Chosen k = {chosen_k} (default from notebook).")
df['cluster_label'] = labels
st.write("Counts per cluster:")
st.write(df['cluster_label'].value_counts())

# Cluster profiles
st.subheader("Cluster Profiles (mean of numerical features)")
cluster_means = df.groupby('cluster_label')[numerical_cols].mean().round(2)
st.dataframe(cluster_means)

st.subheader("Cluster categorical counts")
for col in ['jenis_kelamin', 'jenis_produk', 'pengguna_mobile_banking']:
    st.write(f"Distribution of {col} by cluster")
    ct = df.groupby('cluster_label')[col].value_counts().unstack(fill_value=0)
    st.dataframe(ct)

st.markdown("Notebook: cluster analysis was performed with k=3 and the mean tables & categorical counts were presented for profiling. :contentReference[oaicite:5]{index=5}")

# Statistical tests: ANOVA & T-tests
st.header("Statistical Tests")
st.subheader("ANOVA: jenis_produk vs frekuensi_kunjungi_cabang")
try:
    groups = [df[df['jenis_produk']==g]['frekuensi_kunjungi_cabang'].dropna() for g in sorted(df['jenis_produk'].unique())]
    f_stat, p_val = stats.f_oneway(*groups)
    st.write(f"F-statistic = {f_stat:.4f}, p-value = {p_val:.4f}")
    if p_val < 0.05:
        st.markdown("Result: **Significant** difference in means across product types (p < 0.05). This matches the notebook's ANOVA finding. :contentReference[oaicite:6]{index=6}")
    else:
        st.markdown("Result: No significant difference (p >= 0.05).")
except Exception as e:
    st.error("ANOVA failed: " + str(e))

st.subheader("T-tests: Mobile banking users vs non-users")
mobile = df[df['pengguna_mobile_banking']==1]
non_mobile = df[df['pengguna_mobile_banking']==2]
tt_results = {}
for col in numerical_cols:
    try:
        t, p = stats.ttest_ind(mobile[col].dropna(), non_mobile[col].dropna())
        tt_results[col] = (t, p)
    except Exception:
        tt_results[col] = (np.nan, np.nan)
st.write(pd.DataFrame(tt_results, index=['t_stat', 'p_value']).T)

st.markdown("Notebook concluded there were *no statistically significant* differences for the numerical variables between mobile banking users and non-users (t-tests p >= 0.05). :contentReference[oaicite:7]{index=7}")

# High-value and risky groups
st.header("High-value & Risky Customers")
income_th = df['pendapatan'].quantile(0.75)
bal_th = df['saldo_rata_rata'].quantile(0.75)
txn_th = df['jumlah_transaksi'].quantile(0.75)
st.write(f"High-value criteria: pendapatan > {income_th:.2f}, saldo_rata_rata > {bal_th:.2f}, jumlah_transaksi > {txn_th:.2f}")
high_value = df[(df['pendapatan']>income_th) & (df['saldo_rata_rata']>bal_th) & (df['jumlah_transaksi']>txn_th)]
st.write(f"Number of high-value customers: {len(high_value)}")
if len(high_value)>0:
    st.dataframe(high_value.head(10))
    st.write(high_value[numerical_cols].describe().round(2))
else:
    st.write("No high-value customers by the defined criteria.")

credit_th = df['skor_kredit'].quantile(0.25)
risky = df[df['skor_kredit'] <= credit_th]
st.write(f"Risky criteria: skor_kredit <= {credit_th:.2f}")
st.write(f"Number of risky customers: {len(risky)}")
if len(risky)>0:
    st.dataframe(risky.head(10))
    st.write(risky[numerical_cols].describe().round(2))
else:
    st.write("No risky customers by the defined criteria.")

st.markdown("These high-value / risky group definitions and outputs mirror the notebook analysis. :contentReference[oaicite:8]{index=8}")

# Predicting credit score (supervised modeling)
st.header("Predicting Credit Score (Regression)")

# prepare features
features = ['umur', 'pendapatan', 'saldo_rata_rata', 'jumlah_transaksi', 'frekuensi_kunjungi_cabang',
            'jenis_kelamin', 'jenis_produk', 'pengguna_mobile_banking']
X = df[features]
y = df['skor_kredit']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

if st.button("Train regression models (run)"):
    results = train_and_eval_regressors(X_train, X_test, y_train, y_test)
    res_df = pd.DataFrame({k:{"RMSE":v['RMSE'],"R2":v['R2']} for k,v in results.items()}).T
    st.write("Model results (RMSE, R2):")
    st.dataframe(res_df.style.format("{:.4f}"))
    best = res_df['R2'].idxmax()
    st.success(f"Best model by R2: {best} (R2={res_df.loc[best,'R2']:.4f})")
    st.markdown("Notebook reported negative/low R2 for models and discussed that features may not be sufficient to predict credit score reliably. :contentReference[oaicite:9]{index=9}")
else:
    st.info("Click the button to train & evaluate regression models (quick tests).")

# Final findings panel
st.header("Narrative Findings & Recommendations")
st.markdown("""
- **Data quality:** Notebook reported no missing values or duplicate rows; distributions look reasonable. :contentReference[oaicite:10]{index=10}
- **Univariate / Bivariate:** `pendapatan` and `saldo_rata_rata` are positively correlated; some numeric variables show potential outliers. :contentReference[oaicite:11]{index=11}
- **Product influence:** ANOVA showed `jenis_produk` affects `frekuensi_kunjungi_cabang` (i.e., deposit customers visited branches more often). This was highlighted in the notebook._